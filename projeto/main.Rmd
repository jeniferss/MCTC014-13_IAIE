---
title: "Phenotypic heterogeneity follows a growth-viability tradeoff in response to
  amino acid identity"
author: "Grupo 05"
output: html_document
---

## Artigo

O artigo escolhido tem como título "[Phenotypic heterogeneity follows a growth-viability tradeoff in response to amino acid identity](https://www.nature.com/articles/s41467-024-50602-8#Sec9)", lê-se em português como "A heterogeneidade fenotípica segue um *trade-off* de capacidade de crescimento em resposta à identidade de aminoácidos". Foi publicado na revista [Nature](https://www.nature.com/) em 02 de Agosto de 2024.

## Importando Bibliotecas

Bibliotecas são conjuntos de recursos que podem ser reutilizados em diferentes programas para realização de determinadas funções em comum. No presente trabalho, foram utilizadas as seguintes bibliotecas e ferramentas:

-   [**BiocManager**](https://bioconductor.github.io/BiocManager/articles/BiocManager.html)**:** Ferramenta para instalar e gerenciar pacotes do **Bioconductor**, uma coleção de pacotes para análise de dados de genomas e bioinformática no R.

-   [**tidyverse**](https://www.tidyverse.org/)**:** Um conjunto de bibliotecas no R para manipulação e visualização de dados, que inclui `ggplot2`, `dplyr`, `tidyr`, `readr`, `purrr`, entre outros.

-   [**readxl**](https://cran.r-project.org/web/packages/readxl/index.html)**:** Biblioteca para leitura de arquivos Excel (.xlsx e .xls) no R.

-   [**scales**](https://scales.r-lib.org/)**:** Biblioteca para controle e personalização de escalas e eixos em gráficos no R.

-   [**flexmix**](https://cran.r-project.org/web/packages/flexmix/index.html)**:** Biblioteca parapara modelagem de mistura de modelos com diferentes distribuições.

-   [**mvtnorm**](https://cran.r-project.org/web/packages/mvtnorm/index.html)**:** Bibliotecapara calcular distribuições e funções relacionadas com a distribuição normal multivariada.

```{r}

bibliotecas = c(
  "BiocManager", 
  "tidyverse", 
  "scales",
  "flexmix",
  "mvtnorm",
  "gridExtra"
)

for (biblioteca in bibliotecas) {
  if (!biblioteca %in% installed.packages()) {
    if (biblioteca == "BiocManager") {
      install.packages(biblioteca)
      BiocManager::install("SingleCellExperiment")
      next
    } 
    install.packages(biblioteca)
  }
}

library(ggplot2)
library(dplyr)
library(scales)
library(tidyverse)
library(flexmix)
library(mvtnorm)
library(gridExtra)
```

## Importando dados

Todos os dados gerados ou analisados estão incluídos e disponibilizados no artigo e nas Informações Suplementares. O conteúdo do artigo está sob a licença Creative Commons Atribuição 4.0 Internacional, que permite o uso, compartilhamento, adaptação, distribuição e reprodução, desde que seja dado crédito ao autor original, fornecido um link para a licença e indicadas as alterações feitas.

Dos dados importados, entender-se-á por:

-   GNL: Glutamina;

-   PRO: Prolina;

-   YPD: Extrato de levedura-peptonado-dextrose;

-   NLIM-PRO: Meios limitados de nitrogênio com Prolina;

-   NLIM-GLN: Meios limitados de nitrogênio com Glutamina.

```{r}

rm(list = ls())

PRO.preshift = read.csv(file = './data/source/fig2ab/1230_H9_pre_pRPL28_1.csv')
GLN.preshift = read.csv(file = './data/source//fig2ab/1230_H10_pre_pRPL28_2.csv')

PRO.2h = read.csv(file = './data/source/fig2ab/221121_1630_A1_PRO_GFP.csv')
GLN.2h = read.csv(file = './data/source/fig2ab/221121_1630_A2_GLN_GFP.csv')
PRO.4h = read.csv(file = './data/source/fig2ab/221121_1830_E1_PRO_GFP.csv')
GLN.4h = read.csv(file = './data/source/fig2ab/221121_1830_E2_GLN_GFP.csv')
PRO.6h = read.csv(file = './data/source/fig2ab/221121_2030_A1_PRO_GFP.csv')
GLN.6h = read.csv(file = './data/source/fig2ab/221121_2030_A2_GLN_GFP.csv')
PRO.8h = read.csv(file = './data/source/fig2ab/221121_2230_E1_PRO_GFP.csv')
GLN.8h = read.csv(file = './data/source/fig2ab/221121_2230_E2_GLN_GFP.csv')

PRO2.2h = read.csv(file = './data/source/fig2ab/1430_C2_pRPL28_NLIMPRO.csv')
GLN2.2h = read.csv(file = './data/source/fig2ab/1430_C3_pRPL28_NLIMGLN.csv')
PRO2.4h = read.csv(file = './data/source/fig2ab/1630_F2_pRPL28_NLIMPRO.csv')
GLN2.4h = read.csv(file = './data/source/fig2ab/1630_F3_pRPL28_NLIMGLN.csv')
PRO2.6h = read.csv(file = './data/source/fig2ab/1830_C2_pRPL28_NLIMPRO.csv')
GLN2.6h = read.csv(file = './data/source/fig2ab/1830_C3_pRPL28_NLIMGLN.csv')
PRO2.8h = read.csv(file = './data/source/fig2ab/2030_F2_pRPL28_NLIMPRO.csv')
GLN2.8h = read.csv(file = './data/source/fig2ab/2030_F3_pRPL28_NLIMGLN.csv')

PRO3.preshift = read.csv(file = './data/source/fig2ab/231012_preshift_1.csv')
GLN3.preshift = read.csv(file = './data/source/fig2ab/231012_preshift_2.csv')

PRO3.2h = read.csv(file = './data/source/fig2ab/231012_1440_NLIMPRO.csv')
GLN3.2h = read.csv(file = './data/source/fig2ab/231012_1440_NLIMGLN.csv')
PRO3.4h = read.csv(file = './data/source/fig2ab/231012_1640_NLIMPRO.csv')
GLN3.4h = read.csv(file = './data/source/fig2ab/231012_1640_NLIMGLN.csv')
PRO3.6h = read.csv(file = './data/source/fig2ab/231012_1840_NLIMPRO.csv')
GLN3.6h = read.csv(file = './data/source/fig2ab/231012_1840_NLIMGLN.csv')
PRO3.8h = read.csv(file = './data/source/fig2ab/231012_2040_NLIMPRO.csv')
GLN3.8h = read.csv(file = './data/source/fig2ab/231012_2040_NLIMGLN.csv')

YPD.1840 = read.csv(file = './data/source/fig1d/220707_1840_YPD.csv')
PRO.1830 = read.csv(file = './data/source/fig1d/221121_1830_E1_PRO_GFP.csv')
GLN.1830 = read.csv(file = './data/source/fig1d/221121_1830_E2_GLN_GFP.csv')
```

## Análise Exploratória

Uma análise exploratória é importante para entender os dados que serão utilizados e identificar formas para manipulá-los durante as análises. Abaixo, é apresentado um resumo dos dados importados até o momento, organizados em dataframes. Este resumo inclui o número de observações em cada dataframe e o tipo de dado associado a cada coluna.

*Funções utilizadas:*

-   ls(): lista todos os nomes dos objetos que estão salvos no ambiente de trabalho;

-   sapply(), lapply(): aplica uma função a cada elemento de uma lista;

-   is.data.frame(): verifica se um objeto é do tipo DataFrame.

```{r}

nomesImportados = ls()

dataframesImportados = sapply(
  nomesImportados, 
  function(nome) is.data.frame(get(nome))
)

dataframesNomes = nomesImportados[dataframesImportados]

tiposDeDados = data.frame(
  cabeçalhos = names(PRO.2h), 
  tipos = sapply(PRO.2h, class), 
  stringsAsFactors = FALSE
)

tiposDeDados

numeroObservacoes = function(dataframeName) {
  dataframe = get(dataframeName)
  return(nrow(dataframe))
}

resumoObservacoes = data.frame(
  nome = dataframesNomes,
  observacoes = sapply(dataframesNomes, numeroObservacoes)
)

resumoObservacoes
```

### Mapeamento de dados

*Funções utilizadas:*

-   c(): gera um vetor;

-   rep(): cria um vetor de n repetições do elemento informado;

-   nrow(): retorna o número de linhas de um DataFrame.

```{r}

condicoesPROGLN = c(
  rep('PRO', nrow(PRO.preshift)),
  rep('GLN', nrow(GLN.preshift)),
  rep('PRO', nrow(PRO.2h)),
  rep('GLN', nrow(GLN.2h)),
  rep('PRO', nrow(PRO.4h)),
  rep('GLN', nrow(GLN.4h)),
  rep('PRO', nrow(PRO.6h)),
  rep('GLN', nrow(GLN.6h)),
  rep('PRO', nrow(PRO.8h)),
  rep('GLN', nrow(GLN.8h)),
  rep('PRO', nrow(PRO2.2h)),
  rep('GLN', nrow(GLN2.2h)),
  rep('PRO', nrow(PRO2.4h)),
  rep('GLN', nrow(GLN2.4h)),
  rep('PRO', nrow(PRO2.6h)),
  rep('GLN', nrow(GLN2.6h)),
  rep('PRO', nrow(PRO2.8h)),
  rep('GLN', nrow(GLN2.8h)),
  rep('PRO', nrow(PRO3.preshift)),
  rep('GLN', nrow(GLN3.preshift)),
  rep('PRO', nrow(PRO3.2h)),
  rep('GLN', nrow(GLN3.2h)),
  rep('PRO', nrow(PRO3.4h)),
  rep('GLN', nrow(GLN3.4h)),
  rep('PRO', nrow(PRO3.6h)),
  rep('GLN', nrow(GLN3.6h)),
  rep('PRO', nrow(PRO3.8h)),
  rep('GLN', nrow(GLN3.8h))
)

etapaPROGLN = c(
  rep('preshift', nrow(PRO.preshift)),
  rep('preshift', nrow(GLN.preshift)),
  rep('2h', nrow(PRO.2h)),
  rep('2h', nrow(GLN.2h)),
  rep('4h', nrow(PRO.4h)),
  rep('4h', nrow(GLN.4h)),
  rep('6h', nrow(PRO.6h)),
  rep('6h', nrow(GLN.6h)),
  rep('8h', nrow(PRO.8h)),
  rep('8h', nrow(GLN.8h)),
  rep('2h', nrow(PRO2.2h)),
  rep('2h', nrow(GLN2.2h)),
  rep('4h', nrow(PRO2.4h)),
  rep('4h', nrow(GLN2.4h)),
  rep('6h', nrow(PRO2.6h)),
  rep('6h', nrow(GLN2.6h)),
  rep('8h', nrow(PRO2.8h)),
  rep('8h', nrow(GLN2.8h)),
  rep('preshift', nrow(PRO3.preshift)),
  rep('preshift', nrow(GLN3.preshift)),
  rep('2h', nrow(PRO3.2h)),
  rep('2h', nrow(GLN3.2h)),
  rep('4h', nrow(PRO3.4h)),
  rep('4h', nrow(GLN3.4h)),
  rep('6h', nrow(PRO3.6h)),
  rep('6h', nrow(GLN3.6h)),
  rep('8h', nrow(PRO3.8h)),
  rep('8h', nrow(GLN3.8h))
)

replicacaoPROGLN = c(
  rep('rep1', nrow(PRO.preshift)),
  rep('rep1', nrow(GLN.preshift)),
  rep('rep1', nrow(PRO.2h)),
  rep('rep1', nrow(GLN.2h)),
  rep('rep1', nrow(PRO.4h)),
  rep('rep1', nrow(GLN.4h)),
  rep('rep1', nrow(PRO.6h)),
  rep('rep1', nrow(GLN.6h)),
  rep('rep1', nrow(PRO.8h)),
  rep('rep1', nrow(GLN.8h)),
  rep('rep2', nrow(PRO2.2h)),
  rep('rep2', nrow(GLN2.2h)),
  rep('rep2', nrow(PRO2.4h)),
  rep('rep2', nrow(GLN2.4h)),
  rep('rep2', nrow(PRO2.6h)),
  rep('rep2', nrow(GLN2.6h)),
  rep('rep2', nrow(PRO2.8h)),
  rep('rep2', nrow(GLN2.8h)),
  rep('rep3', nrow(PRO3.preshift)),
  rep('rep3', nrow(GLN3.preshift)),
  rep('rep3', nrow(PRO3.2h)),
  rep('rep3', nrow(GLN3.2h)),
  rep('rep3', nrow(PRO3.4h)),
  rep('rep3', nrow(GLN3.4h)),
  rep('rep3', nrow(PRO3.6h)),
  rep('rep3', nrow(GLN3.6h)),
  rep('rep3', nrow(PRO3.8h)),
  rep('rep3', nrow(GLN3.8h))
)

```

```{r}

dadosPROGLN = bind_rows(
  PRO.preshift, 
  GLN.preshift, 
  PRO.2h, 
  GLN.2h, 
  PRO.4h, 
  GLN.4h, 
  PRO.6h, 
  GLN.6h, 
  PRO.8h, 
  GLN.8h,
  PRO2.2h, 
  GLN2.2h, 
  PRO2.4h, 
  GLN2.4h, 
  PRO2.6h, 
  GLN2.6h, 
  PRO2.8h, 
  GLN2.8h,
  PRO3.preshift, 
  GLN3.preshift, 
  PRO3.2h, 
  GLN3.2h, 
  PRO3.4h, 
  GLN3.4h, 
  PRO3.6h, 
  GLN3.6h, 
  PRO3.8h, 
  GLN3.8h
)

dadosPROGLN$conditions = condicoesPROGLN
dadosPROGLN$step = etapaPROGLN
dadosPROGLN$replicate = replicacaoPROGLN

head(dadosPROGLN)
```

```{r}

sumarioPROGLN = dadosPROGLN %>%
  group_by(
    conditions,
    step,
    replicate
  ) %>%
  summarize(
    mean_pRPL28 = mean(BL1.H),
    sd_pRPL28 = sd(BL1.H),
    cv_pRPL28 = sd_pRPL28/mean_pRPL28,
    
    mean_size = mean(FSC.H),
    sd_size = sd(FSC.H),
    cv_size = sd_size/mean_size,
    
    .groups = "keep"
  )

head(sumarioPROGLN)
```

```{r}

estatisticasPROGLN = sumarioPROGLN %>%
  group_by(step, conditions) %>%
  summarize(
    mean_mean_pRPL28 = mean(mean_pRPL28),
    mean_sd_pRPL28 = mean(sd_pRPL28),
    mean_cv_pRPL28 = mean(cv_pRPL28),
    
    se_mean_pRPL28 = sd(mean_pRPL28)/ sqrt(n()),
    se_sd_pRPL28 = sd(sd_pRPL28)/ sqrt(n()),
    se_cv_pRPL28 = sd(cv_pRPL28)/ sqrt(n()),
    
    mean_mean_size = mean(mean_size),
    mean_sd_size = mean(sd_size),
    mean_cv_size = mean(cv_size),
    
    se_mean_size = sd(mean_size)/ sqrt(n()),
    se_sd_size = sd(sd_size)/ sqrt(n()),
    se_cv_size = sd(cv_size)/ sqrt(n()),
    
    .groups = "keep"
  )

head(estatisticasPROGLN)
```

### Figura 01

Nesta etapa da análise, o objetivo era verificar se a bimodalidade, tanto na distribuição da fluorescência de pRPL28 quanto no tamanho das células, como sugerido pelos dados de scRNA-seq, pode ser detectada em meios limitados de nitrogênio com prolina ou glutamina como fontes de nitrogênio, mas não em meios ricos, como o extrato de levedura-peptonado-dextrose.

![](images/41467_2024_50602_Fig1_HTML.webp)

```{r}

condicoesBimodalidade = c(
  rep('YPD', nrow(YPD.1840)),
  rep('NLIM-PRO', nrow(PRO.1830)),
  rep('NLIM-GLN', nrow(GLN.1830))
)

bimodalidade = bind_rows(YPD.1840, PRO.1830, GLN.1830)
bimodalidade$conditions = condicoesBimodalidade

valorMin <- min(c(bimodalidade$BL1.H, bimodalidade$FSC.H), na.rm = TRUE)
valorMax <- max(c(bimodalidade$BL1.H, bimodalidade$FSC.H), na.rm = TRUE)

gerarGraficoBimodalidade = function(valorX, legendaX) {
  grafico = ggplot(
    bimodalidade, 
    aes(x = valorX, colour = conditions)
  ) + 
  geom_density(size = 1) +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10 ^ x),
    labels = trans_format("log10", math_format(10 ^ .x)),
    limits = c(valorMin, valorMax)
  ) +
  theme_bw(
    base_size = 10
  ) +
  labs(
    colour = "Condições",
    x = legendaX,
    y = "Densidade (a.u.)"
  )
  
  return(grafico)
}

fluorescencia = gerarGraficoBimodalidade(
  valorX = bimodalidade$BL1.H, 
  legendaX = "pRPL28 fluorescência (BL1-H)"
)

tamanhoCelula = gerarGraficoBimodalidade(
  valorX = bimodalidade$FSC.H, 
  legendaX = "Tamanho da célula (FSC-H)"
)

grid.arrange(fluorescencia, tamanhoCelula, ncol = 1)
```

### Figura Suplementar 6

A figura suplementar 6 se trata do Coeficiente de Variação, que é uma medida para expressar a variabilidade de uma variável em relação à sua média.

![](images/clipboard-522279152.png)

```{r}

variabilidadeTamanho = ggplot(
  estatisticasPROGLN, 
  aes(x = step, y = mean_cv_size, fill = conditions)
) +
    geom_bar(
      stat = "identity",
      position = position_dodge(width = 0.9),
      width = 0.7
    ) +
    geom_point(
      data = sumarioPROGLN, 
      aes(
        x = step, 
        y = cv_size, 
        group = conditions
      ), 
      position = position_dodge(width = 0.9),
      size = 0.8,
      color = "gray"
    ) +
    geom_errorbar(
      aes(
        ymin = mean_cv_size - se_cv_size,
        ymax = mean_cv_size + se_cv_size
      ),
      position = position_dodge(width = 0.9),
      width = 0.4
    ) +
    ylim(0, 0.7) +
    theme_bw(
      base_size = 7
    ) +
    labs(
      colour = "Condições",
      y = "Coeficiente de Variação (Tamanho)",
      x = "Tempo"
    )


variabilidadeFlorescencia = ggplot(
  estatisticasPROGLN, 
  aes(x = step, y = mean_cv_pRPL28, fill = conditions)
) +
    geom_bar(
      stat = "identity",
      position = position_dodge(width = 0.9),
      width = 0.7
    ) +
    geom_point(
      data = sumarioPROGLN, 
      aes(
        x = step, 
        y = cv_pRPL28, 
        group = conditions
      ), 
      position = position_dodge(width = 0.9), 
      size = 0.8,
      color = "gray"
    ) +
    geom_errorbar(
      aes(
        ymin = mean_cv_pRPL28 - se_cv_pRPL28,
        ymax = mean_cv_pRPL28 + se_cv_pRPL28
      ),
      position = position_dodge(width = 0.9),
      width = 0.4
    ) +
    ylim(0, 0.7) +
    theme_bw(
      base_size = 7
    ) +
    labs(
      colour = "Condições",
      y = "Coeficiente de Variação (Flourescência)",
      x = "Tempo"
    )


grid.arrange(
  variabilidadeFlorescencia, 
  variabilidadeTamanho, 
  ncol = 1
)
```

Em seguida, foi realizado um teste t não pareado, em que:

-   **Hipótese Nula (H₀):** Não há diferença significativa no tamanho médio das células entre os meios limitados de nitrogênio com prolina e glutamina após 8 horas de cultivo.

-   **Hipótese Alternativa (H₁):** Há uma diferença significativa no tamanho médio das células entre os meios limitados de nitrogênio com prolina e glutamina após 8 horas de cultivo.

Entretanto, é importante lembrar que uma das premissas para a aplicação do teste T é a normalidade dos dados. Para verificar se os dados seguem uma distribuição normal, pode-se realizar o teste de Shapiro-Wilk. Neste teste, a hipótese nula (H₀) é de que os dados são provenientes de uma distribuição normal.

```{r}

PRO8H = sumarioPROGLN %>%
  filter(step == "8h" & conditions =="PRO") %>% pull(cv_size)

GLN8H = sumarioPROGLN %>%
  filter(step == "8h" & conditions =="GLN") %>% pull(cv_size)

shapiro.test(PRO8H)
shapiro.test(GLN8H)
```

Como o p-valor obtido foi maior que o nível de significância padrão de 5%, não há evidências suficientes para rejeitar a hipótese nula, sugerindo que os dados podem ser considerados como de uma distribuição normal, e pode-se aplicar o teste T.

```{r}

t.test(PRO8H, GLN8H, paired = FALSE, alternative = "two.sided")
```

De acordo com os resultados do teste, a hipótese nula foi rejeitada, pois o p-valor obtido foi menor que o nível de significância padrão de 5%. Isso indica que há uma diferença significativa no tamanho médio das células entre os meios limitados de nitrogênio com prolina e glutamina após 8 horas de cultivo.

### Figura 2

Nessa etapa da análise, as células foram agrupadas com base em duas características principais: o tamanho da célula e a fluorescência de pRPL28, isso para identificar diferentes subpopulações dentro da amostra de células.

![](images/41467_2024_50602_Fig2_HTML.webp)

*Conceitos importantes:*

-   *Clustering* multivariado: combinação de múltiplas variáveis para encontrar padrões ou agrupamentos nos dados.

```{r}

flexmixMVClustering = function(
    dados, 
    limiarProbabilidade=0.95, 
    dimensoes=c("FSC.H", "BL1.H"),
    numeroClusters=2,
    clusterInicial=NULL
){
  # Realiza o clustering multivariado
  # dados : data frame com dados de fluxo
  # limiarProbabilidade : valor para o limiar para atribuir células ao cluster 
  # dimensoes : dimensões para realizar o clustering 
  
  modelo1 = FLXMCmvnorm()
  modelo2 = FLXMCmvnorm()
  
  dadosMVFit = dados %>% 
    dplyr::select(all_of(dimensoes))
  
  set.seed(123)
  
  if (is.null(clusterInicial)) {
    ajusteFlex = flexmix(
      as.matrix(dadosMVFit) ~ 1, 
      data = dadosMVFit, 
      k = numeroClusters, 
      model = list(modelo1, modelo2)
    )
  } else {
    ajusteFlex = flexmix(
      as.matrix(dadosMVFit) ~ 1, 
      data = dadosMVFit, 
      k = numeroClusters, 
      model = list(modelo1, modelo2), 
      cluster = clusterInicial
    )
  }
  
  probabilidades = posterior(ajusteFlex)
  dadosClusterizados = cbind(dados, probabilidades)
  
  parametrosCluster1 = parameters(ajusteFlex, component=1)[[1]]
  parametrosCluster2 = parameters(ajusteFlex, component=2)[[1]]
  
  mediasClusters = c(
    parameters(ajusteFlex, component=1)[[1]][1],
    parameters(ajusteFlex, component=2)[[1]][1]
  )
  
  if (which.min(mediasClusters) == 1) {
    dadosClusterizados = dplyr::rename(
      dadosClusterizados, "lowProb" = "1"
    )
    dadosClusterizados = dplyr::rename(
      dadosClusterizados, "highProb" = "2"
    )
  } else {
    dadosClusterizados = dplyr::rename(
      dadosClusterizados, "lowProb" = "2"
    )
    dadosClusterizados = dplyr::rename(
      dadosClusterizados, "highProb" = "1"
    )
  }
  
  dadosClusterizados = dadosClusterizados %>% 
    mutate(
      class = if_else(
        lowProb > limiarProbabilidade, 
        "Low", 
        if_else(
          highProb > limiarProbabilidade , "High", "Unknown"
        )
      )
    )
  
  dadosClusterizados
}
```

Funções Utilizadas:

-   *FLXMCmvnorm()* : cria um modelo gaussiano/multivariado usando o pacote flexmix.

```{r, warning = FALSE}

modelo1 = FLXMCmvnorm()
modelo2 = FLXMCmvnorm()

dadosMultivariados = dadosPROGLN %>%
  filter(step == "4h" & conditions == "PRO" & replicate == "rep1") %>%
  dplyr::select(all_of(c("FSC.H", "BL1.H")))

set.seed(123)

ajusteModelo = flexmix(
  as.matrix(dadosMultivariados) ~ 1,
  data = dadosMultivariados,
  k = 2,
  model = list(modelo1, modelo2)
)

paramsModelo1 = parameters(ajusteModelo, component=1)[[1]]
paramsModelo2 = parameters(ajusteModelo, component=2)[[1]]

modelo1Limites = c(paramsModelo1[1], paramsModelo1[2])
Modelo2Limites = c(paramsModelo2[1], paramsModelo2[2])
 
coeficienteVariacao = (
  Modelo2Limites[2] - modelo1Limites[2]
  )/(
    Modelo2Limites[1] - Modelo2Limites[1]
  )

dadosClusterizadosPROGLN = flexmixMVClustering(
  dadosPROGLN %>%
    filter(step=="4h" & conditions=="PRO" & replicate=="rep1")
)

mediasdadoSemClassificacao = dadosClusterizadosPROGLN %>%
  filter(class == "Unknown") %>%
  summarise(across(c(FSC.H, BL1.H), mean))

pontoMedio = c(
  mediasdadoSemClassificacao$FSC.H, 
  mediasdadoSemClassificacao$BL1.H
)

coeficienteVariacaoInverso = - 1 / coeficienteVariacao

intercepto = pontoMedio[2] - coeficienteVariacaoInverso * pontoMedio[1]

divisaoDados = dadosPROGLN %>%
  mutate(
    hard_assign = ifelse(
      BL1.H < coeficienteVariacaoInverso * FSC.H + intercepto, "Low", "High"
    )
  )

taxaDivisaoDados = divisaoDados %>%
  dplyr::select(c("conditions", "step", "replicate", "hard_assign")) %>%
  group_by(conditions, step, replicate) %>%
  summarize(
    count_high = sum(hard_assign == "High"),
    count_low = sum(hard_assign == "Low"),
    .groups = "keep"
  ) %>%
  mutate(
    ratio_low_to_high = count_low / count_high
  )

mapeamentoHoras = c("2h" = 2, "4h" = 4, "6h" = 6, "8h" = 8,  "preshift" = 0)
ordenamentoHoras = c("preshift", "2h", "4h", "6h", "8h")

taxaDivisaoDados$numeric_time = mapeamentoHoras[
  as.character(taxaDivisaoDados$step)
]

taxaDivisaoDados$step = factor(taxaDivisaoDados$step, levels = ordenamentoHoras)
 
mediaTaxas = taxaDivisaoDados %>%
  group_by(step, conditions) %>%
  summarize(
    mean_ratio = mean(ratio_low_to_high),
    sd_ratio = sd(ratio_low_to_high) / sqrt(n()),
    .groups = "keep"
  )

ggplot(
  mediaTaxas,
  aes(x = step, y = mean_ratio, fill = conditions)
) +
  geom_bar(
    stat = "identity",
    position = position_dodge(width = 0.9),
    width = 0.7
  ) +
  geom_errorbar(
    aes(
      ymin = mean_ratio - sd_ratio, 
      ymax = mean_ratio + sd_ratio
    ),
    position = position_dodge(width = 0.9),
    width = 0.4
  ) +
  geom_point(
    data = taxaDivisaoDados,
    aes(
      x = step, 
      y = ratio_low_to_high, 
      group = conditions
    ),
    position = position_dodge(width = 0.9),
    size = 0.8,
    colour="grey"
  ) +
  ylim(0, 2) +
  theme_bw(base_size = 8) +
  labs(
    colour = "Condições",
    y = "Razão Low para High",
    x = "Tempo"
  )
```

```{r}

PRO4H = taxaDivisaoDados %>%
  filter(step == "4h" & conditions =="PRO") %>% 
  pull(ratio_low_to_high)

GLN4H = taxaDivisaoDados %>% 
  filter(step == "4h" & conditions =="GLN") %>%
  pull(ratio_low_to_high)

t.test(PRO4H, GLN4H, paired = FALSE, alternative = "two.sided")
```

## Referências

[1]
